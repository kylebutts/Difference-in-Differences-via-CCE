\documentclass[12pt,fleqn]{article}
\usepackage{paper}

\title{\textsc{Simple Treatment Effect Estimation in Fixed-$T$ Panels with Interactive Fixed Effects}\thanks{The authors would like to thank Co-Editor Ivan Canay, an Associate Editor, and two anonymous referees for many valuable comments and suggestions. Westerlund would also like to thank the Knut and Alice Wallenberg Foundation for financial support through a Wallenberg Academy Fellowship.}}
\author{
    \and Nicholas Brown\\
    {\small Queen's University} \and Kyle Butts\\
    {\small University of Arkansas} \and Joakim Westerlund\thanks{Corresponding author: Department of Economics, Lund University, Box 7082, 220 07 Lund, Sweden. Telephone: +46 46 222 8997. Fax: +46 46 222 4613. E-mail address: \texttt{joakim.westerlund@nek.lu.se}.}\\
    {\small Lund University}\\
    {\small and}\\
    {\small Deakin University}
}
\date{\today}

\begin{document}
\maketitle

%\doublespacing

\begin{abstract}
  \setlength{\baselineskip}{0.83cm}
  The present paper proposes a simple approach to treatment effects estimation in linear panel data models that is valid when the number of time periods is small and the parallel trends condition is violated due to the presence of interactive fixed effects. The procedure allows the covariates to be affected by treatment and enables separation of the part of the estimated treatment effect that is due to the covariates from the part that is not. The asymptotic properties of the procedure are established and their accuracy in small samples is investigated using Monte Carlo simulations. The procedure is illustrated using as an example the effect of increased trade competition on firm markups in China.
  \end{abstract}
  
  \setlength{\baselineskip}{0.83cm}
  
  \textbf{JEL Classification:} C31, C33, C38.
  
  \textbf{Keywords:} Treatments effects estimation; difference-in-differences; interactive fixed effects; common correlated effects.
  
  \section{Introduction}
  
  Consider a panel data set comprised of $N$ cross-sectional units and $T$ time periods. Treatment effects studies based on this type of data typically estimate linear models with additive unit and time fixed effects. Such fixed effects are consistent with the so-called ``parallel trends'' assumption, which demands that the average outcomes for treated and untreated cross-sectional units must follow the same path over time in absence of treatment. Because this assumption is implausible in many settings, much effort has been spent trying to control for violations through the inclusion of covariates. A common approach estimates either time-varying slopes on time-invariant/`baseline' covariates or unit-varying slopes on covariates that only vary over time (see, for example, \citealp{Callaway_Karami_2020}, and \citealp{kim_oka2014}). The idea is that deviations from parallel trends can be modeled as a product of two terms; one captures the trend itself, while the other measures the extent to which the impact of this trend is equal, or parallel, across units. The problem is that many drivers of non-parallel trending are unobserved and lack good proxies.\footnote{For example, in studies with time-varying-only covariates, deterministic linear and quadratic trends are often the only candidates even though there is plenty of evidence to suggest that they are not enough (see, for example, \citealp{kim_oka2014}).} The approach is also wasteful, in the sense that economists often have access to panel data on covariates that vary over both units and time, and that are likely more informative than covariates that vary only over one of the two dimensions. When these covariates are affected by treatment, including the covariates in the model will yield biased treatment effect estimates. Hence, while there are covariates available that could be used to control for non-parallel trends, they are rarely included since this is likely to do more damage than good (see \citealp{Caetano_Callaway_Payne_Rodrigues_2022}, for a recent discussion).
  
  The present paper is motivated by the observations made in the previous paragraph. The purpose is to develop a new approach to treatment effects estimation that allows for a broad range of non-parallel trends and treatment-affected covariates. As a starting point, we consider an ``interactive'' fixed effects specification, in which the unit fixed effects, also called ``factor loadings'', interact multiplicatively with the time effects, also called ``common factors''.\footnote{When we refer to ``interactive fixed effects'', we mean that both factors and factor loadings are treated as non-random parameters.} This specification contains the conventional additive two-way fixed effect model as a special case. It captures the idea that deviations from parallel trends can be modelled as macroeconomic shocks, or common factors, that impact each unit differently through specific multipliers, or loadings. The main advantage when compared to the usual approach of including covariates that are either unit- or time-invariant is that both factors and loadings can be treated as unknown.
  
  The present paper is not the first to allow for interactive fixed effects in the treatment effects context; however, it is the first to do so while at the same time allowing for treatment-affected covariates. In fact, the new approach does not only allow for such treatment-affected covariates, but it enables researchers to separate the part of the treatment effect that is due to the covariates from the part that is not. As far as we are aware, there is currently no other treatment effects approach with this level of flexibility.
  
  The new approach is not only flexible but is also very simple and user friendly. \citet{Gobillon_Magnac_2016}, and \citet{Xu_2017} allow for interactive effects that are dealt with using versions of the principal components (PC)-based approach of \citet{bai2009panel}. However, the PC approach is based on solving a non-convex optimization problem, which means that it is not only computationally costly but it can also be difficult to get to converge. Even if it does converge, it may not be to the global optimum (see \citealp{Moon_Weidner_2019}). There are also generalized method of moments (GMM)-based approaches, such as those of \citet{Callaway_Karami_2020} and \citet{brown2022generalized}, but they require valid instruments that might not be available in practice. Both PC and GMM require that the number of unobserved factors can be accurately estimated, which is known to be difficult (see, for example, \citealp{moon2015linear}, and \citealp{breitung2021alternative}). Even if the estimator is accurate, the resulting PC and GMM estimators still suffer from ``post-selection bias'' (see \citealp{leeb2005model}). The new procedure uses only ordinary least squares (OLS) operations and there is no need for accurate estimation of the number of factors.
  
  Another attractive feature of the new approach is that $T$ does not have to be large. Initially proposed as dimension reduction techniques, interactive fixed effects approaches tend to be ``data-hungry''. A very common requirement is that both $T$ and $N$ are both large (see \citealp{chan2022pcdid}, \citealp{Gobillon_Magnac_2016}, \citealp{Xu_2017}, and \citealp{Arkhangelsky_2021_synthetic_DID}), which is a problem because in treatment effects studies $T$ is often small (see \citealp{Bertrand_etal_2004}, for a survey). The new procedure accounts for this smallness of $T$ and is as a result widely applicable.
  
  The attractiveness of the new approach is achieved in part by our novel use of the common correlated effects (CCE) approach of \citet{pesaran2006estimation}, which has a closed form, allows $T$ to be fixed, and does not require estimation of the number of factors (see \citealp{westerlund2019cce}, for a discussion).\footnote{\citet{Eberhardt2022} recently applied CCE in the treatment effects context to estimate the impact of democratisation on long-run growth. This other estimator is, however, materially different from ours, and with unknown finite sample and asymptotic properties.} The ``common-correlated effects'' assumption requires the researcher to have access to a set of covariates that are impacted by the same set of common factors as the outcome variable. Using the information from these covariates (including the outcome variable) allows us to estimate the confounding shocks and isolate the causal effect of interest. The main requirement is that the number of factors cannot be larger than the number of observables that loads on those factors, which is a testable restriction.
  
  The main object of interest is the average treatment effect on the treated (ATT), which is the average difference between the actual and counterfactual post-treatment outcomes of treated cross-sectional units. This average cannot be directly calculated since the counterfactual outcome is unobserved. We therefore use the CCE approach to estimate it. The proposed treatment effect CCE estimator, dubbed ``TECCE'', is computed in three simple steps. We begin by estimating the common factors using cross-sectional averages of all the observables from the untreated sample. We then estimate the factor loadings by regressing the outcome variable for each cross-sectional unit on the first-step factor estimates. In the third and final step, we use the estimated interactive fixed effects, which is simply the product of the first- and second-step factor and loading estimates, to estimate the counterfactual outcomes. The estimated ATT is the average difference between the observed treated and estimated counterfactual outcomes.
  
  The new estimator is shown to be consistent and asymptotically normal under general conditions provided only that the number of treated and untreated units is large, a result that is verified in finite samples by means of Monte Carlo simulations. This result is noteworthy because the TECCE estimation procedure described in the previous paragraph does not require explicit accounting of the covariates in steps two and three. In spite of this, consistency and asymptotic normality hold regardless of whether the covariates are affected by treatment. Researchers interested in studying the extent to which the covariates contributes to the ATT can do so by repeating steps two and three of the estimation procedure while conditioning on the observed covariates. This procedure gives an estimator of the part of the ATT that is not due to the covariates, which can be subtracted off the initial ATT estimator to produce an estimator of the part of the ATT that is due to the covariates.
  
  As an empirical illustration, we consider the effect of China's accession into the World Trade Organization (WTO) in 2001 on the dispersion of industry-level markups. Our results suggest that the increased competition generated by the accession lead to reduced markup dispersion, and that almost half of this reduction was brought about by lower marginal cost dispersion.
  
  The rest of the paper is structured as follows. Section 2 presents the model and defines the ATT, the estimation of which is the concern of Section 3. Sections 4, 5 and 6 contain the asymptotic, Monte Carlo and empirical studies, respectively. Section 7 concludes. All proofs are relegated to the online appendix.
  
  \section{The model}
  
  We are interested in estimating the ATT of a particular treatment on some outcome variable $y_{i,t}$, observable for $i\in \{1,...,N\}$ cross-sectional units and $t\in\{1,...,T\}$ time periods. We allow for the possibility that the $N$ units can be divided into groups within which treatment timing is the same. There are $G < \infty$ such groups indexed by $g \in \{1,...,G\}$. Treated units never leave their groups but remain exposed for all periods after entering treatment; that is, treatment is of the ``staggered'' type. Untreated units are members of group $g=0$.
  
  The timing of the treatment could be viewed as the outcome of a random process that is dealt with through suitable conditioning. In this paper we instead follow \citet{borusyak2021revisiting}, and view the treatment timing as fixed, which has the advantage that it is semi-parametric because no assumption on the distribution of the treatment timing needs to be made. It is particularly well suited for applications where treatment timing is not explicitly randomized, as in our empirical illustration of Section 6. Let us therefore denote by $g_i \in\{ 0,...,G \}$ a variable stating the group membership of cross-sectional unit $i$, and by $\mathcal{I}_g := \{i: g_i = g \in\{ 0,...,G \}\} \subset \{1,...,N\}$ the set of cross-sectional units that are members of group $g$, where $a:=b$ means that $a$ is defined by $b$. The set of untreated units is therefore denoted $\mathcal{I}_0$, and it is convenient to let $\mathcal{I}_0^c := \{1,...,N\}\backslash \mathcal{I}_0$ denote the set of treated units. The number of cross-sectional units within group $g$ is given by the cardinality $N_g := |\mathcal{I}_g|$. Exact conditions on $N_0,...,N_G$ will be specified later. For now, we just assume that these quantities are ``large''.\footnote{Hence, as usual, we assume that there are both treated and untreated units in the sample. The condition that $N_0,...,N_G$ are all large is also very common, although it is not always articulated in the same way as here. Many studies assume the probability of treatment is strictly positive (see, for example, \citealp{Abadie_2005}, \citealp{Callaway_SantAnna_2020}, and \citealp{SantAnna_Zhao2020}, for discussions), which in the current fixed treatment allocation context is tantamount to requiring that $N_g/N \to \delta >0$ as $N_g,\,N \to \infty$. \citet{chan2022pcdid} estimate treatment effects for each cross-sectional unit in the treated group using only the time series variation. While this estimator do not require a large number of treated units, their pooled estimator does.} We denote $T_{0}$ as the first period before any unit is treated, so that the first treatment starts in period $T_0+1$. Unlike $N_0,...,N_G$, the number of pre-treatment periods $T_{0}$ does not have to be large, provided that it is larger than the number of estimated factors. We describe this condition later. The start of the treatment of group $g > 0$ is denoted $t_g$.
  
  Denote by $y_{i,t}(g)$ the ``potential'' outcome of cross-sectional unit $i$ had it been member of group $g$ in period $t$. The observed outcome for unit $i$ at time $t$ is given by $y_{i,t} := y_{i,t}(g_i)$. In this notation, the unit-specific treatment effect for a unit $i$ that is member of treatment group $g_i = g > 0$ in post-treatment periods $t > T_0$ is given by
  \begin{align}
  \Delta_{i,t} := y_{i,t} - y_{i,t}(0) \label{te}
  \end{align}
  (see \citealp{borusyak2021revisiting}, for a similar definition). Because we do not observe $y_{i,t}(0)$ for treated units in post-treatment periods, $\Delta_{i,t}$ must be treated as unknown and estimated from the data. Of course, because $T$ is fixed, accurate estimation of $\Delta_{i,t}$ itself is impossible. The object of interest is therefore not $\Delta_{i,t}$ but the ATT, $\mathbb{E}(\Delta_{i,t})$, which we now characterize.
  
  \bigskip
  
  \noindent \textbf{Assumption 1.} $\Delta_{i,t} = \mathrm{ATT}_{g,t} + \upsilon_{i,t}$, where $\mathrm{ATT}_{g,t}$ is non-random and $\upsilon_{i,t}$ is a mean zero random error that is independent of all other random elements of the model.
  
  \bigskip
  
  Assumption 1 implies that $\mathbb{E}(\Delta_{i,t} ) = \mathrm{ATT}_{g,t}$, which is the same ``group-time'' ATT considered by \citet{Callaway_SantAnna_2020} (see also \citealp{Callaway_Karami_2020}, and \citealp{Xu_2017}).\footnote{Most studies in the literature do not use random coefficient conditions like Assumption 1 (see \citealp{chan2022pcdid}, and \citealp{Gobillon_Magnac_2016}, for exceptions), but state their conditions directly in terms of the (conditional) expectations of those random coefficients.} Except for the constancy-within-groups condition, the ATT is unrestricted, which means that it is allowed to vary freely over both groups and time. One implication of this is that the effect of the treatment need not take place abruptly but can be gradual in nature. This is in contrast to existing studies that typically make quite strong assumptions about the variability of the ATT. In particular, it is common to assume that the ATT is time-invariant (see \citealp{Abadie_2005}, \citealp{chan2022pcdid}, and \citealp{Gobillon_Magnac_2016}, to mention a few).\footnote{\citet{chan2022pcdid} assume that both $N$ and $T$ are large. This allows them to estimate unit-specific treatment effects, which is not possible when $T$ is fixed.}
  
  \bigskip
  
  \noindent \textbf{Assumption 2.} $y_{i,t} = y_{i,t}(0)$ for $t \leq T_0$.
  
  \bigskip
  
  Assumption 2 is similar to Assumption 11 in \citet{Callaway_Karami_2020}, and Assumption 3 in \citet{Callaway_SantAnna_2020}. It requires that there is no treatment effect before any unit receives treatment. Once one group enters treatment, however, anticipation is not ruled out for other groups. This condition seems reasonable because before the first group enters treatment, the units might not know what to expect. Once treatment roll-out has commenced, however, it is possible that not-yet-treated units learn from the treated.
  
  We typically do not observe $y_{i,t}$ in isolation but together with covariates whose outcome may again depend on treatment status. In our empirical illustration, we estimate the effect of China's accession into WTO on industry-level markup dispersion while controlling for the dispersion in marginal costs. According to theory, increased competition may affect markups directly through changes in market structure and indirectly through changes in marginal costs. We therefore introduce the $m\times 1$ vector $\*x_{i,t}(g)$, whose realized value is given by $\*x_{i,t} := \*x_{i,t}(g_i)$.\footnote{Note how $\*x_{i,t} = \*x_{i,t}(0)$ for $t \leq T_0$ is a necessary condition for Assumption 2. We therefore require that $\*x_{i,t}$ satisfies the same anticipation condition as $y_{i,t}$.}
  
  \bigskip
  
  \noindent \textbf{Assumption 3.}
  \begin{align*}
  y_{i,t}(0) = \+\beta_i'\*x_{i,t}(0) + \+\alpha_i'\*f_t + \varepsilon_{i,t},
  \end{align*}
  where $\+\beta_i$ is a $m\times 1$ vector of slope coefficients, $\*f_t$ is a $r \times 1$ vector of unobservable common factors, $\+\alpha_i$ is a $r\times 1$ vector of factor loadings, and $\varepsilon_{i,t}$ is a mean zero random error. Both $\*f_t$ and $\+\alpha_i$ are assumed to be non-random.
  
  \bigskip
  
  Assumption 3 specifies $y_{i,t}(0)$ as a linear function of $\*x_{i,t}(0)$, which is a very common requirement in the empirical literature. There are some exceptions based on non-parametric approaches (see, for example, \citealp{Abadie_2005}, \citealp{Callaway_SantAnna_2020}, and \citealp{SantAnna_Zhao2020}). However, these suffer from the ``curse of dimensionality'' problem, the solution of which typically involves imposing additional structure, and still the small-sample properties can be unacceptably poor unless sample sizes are very large. Non-parametric approaches typically also place strong distributional assumptions directly on the observed data. A very common condition is that $y_{i,t}$ and $\*x_{i,t}$ are independently and identically distributed (iid) over $i$, which is unrealistic.
  
  The interactive fixed effects are given by $\+\alpha_i'\*f_t$. The standard approach in the treatment effects literature is to include additive time and unit fixed effects (see, for example, \citealp{Caetano_Callaway_Payne_Rodrigues_2022}, and \citealp{Callaway_Karami_2020}, for recent discussions). Such effects are nested within our interactive specification, as is clear from noting that $\+\alpha_i'\*f_t = \eta_i + \theta_t$ in the special case when $\*f_t = [1, \theta_t]'$ and $\+\alpha_i = [\eta_i, 1]'$. A major advantage of the interactive specification when compared to the additive one is that it accommodates violations of the parallel trends condition. Indeed, unless $\*f_t = \*f$ for all $t$, trends will not be parallel unless $\+\alpha_i \ne \+\alpha_j$ for all pairs $i$ and $j$.\footnote{The parallel trends condition requires that $\mathbb{E}[\Delta y_{i,t}(0)|\Delta \*x_{i,t}(0) ] = \mathbb{E}[\Delta y_{j,t}(0)|\Delta\*x_{j,t}(0) ]$ for att $i \in \mathcal{I}_0$, $j \in \mathcal{I}_0^c$ and $t > T_0$, which in terms of the model in Assumption 1 reads $\+\beta_i'\Delta\*x_{i,t}(0) + \+\alpha_i'\Delta\*f_t = \+\beta_j'\Delta\*x_{j,t}(0) + \+\alpha_j'\Delta\*f_t$ (see, for example, \citealp{Callaway_SantAnna_2020}, or \citealp{chan2022pcdid}). A necessary condition for this last equality to hold is that $\+\alpha_i = \+\alpha_j$ for $i \in \mathcal{I}_0$ and $j \in \mathcal{I}_0^c$, which in turn requires $\+\alpha_i = \+\alpha_j$ for all $(i,j)\in \{1,...,N\}$.} Hence, by leaving $\*f_t$ and $\+\alpha_i$ unrestricted, we can accommodate very general forms of non-parallel behaviour. In fact, the interactive effects specification considered here is general even when compared to other specifications of the same type, which typically assume that either $\*f_t$ or $\+\alpha_i$, or both, follow certain probability laws (see, for example, \citealp{chan2022pcdid}, \citealp{Gobillon_Magnac_2016}, and \citealp{Xu_2017}).\footnote{An example of a common assumption is that $\*f_t$ is generated from a stationary stochastic process (see, for example, \citealp{Gobillon_Magnac_2016}, and \citealp{Xu_2017}), which is likely restrictive in the present context because it rules out factors that are, for example, breaking or trending.}
  
  \bigskip
  
  \noindent \textbf{Assumption 4.}
  \begin{align*}
  \*x_{i,t}(0) = \+\lambda_i'\*f_t + \*v_{i,t},
  \end{align*}
  where $\+\lambda_i$ is a $r \times m$ matrix of non-random factor loadings and $\*v_{i,t}$ is a $m \times 1$ vector of mean zero errors that are independent of $\varepsilon_{i,t}$.
  
  \bigskip
  
  Assumption 4 allow $\*x_{i,t}(0)$ to load on the same set of factors as $y_{i,t}(0)$, which means that it may be endogenous. Hence, in contrast to much of the previous literature, here treatment is not the only source of endogeneity (see \citealp{Caetano_Callaway_Payne_Rodrigues_2022}, for a discussion). The common dependence on $\*f_t$ is consistent with the empirical observation that many variables are affected by the same common shocks (see, for example, \citealp{westerlund2019cce}). The factors need not be the same, though, as loadings may be zero. There might therefore be factors that are unique to $\*x_{i,t}(0)$ and/or $y_{i,t}(0)$. The condition that $\*x_{i,t}(0)$ loads linearly on $\*f_t$ rules out specifications featuring, for example, dummy variables, powers or products of the covariates. However, additional covariates can be easily accommodated provided that they satisfy standard exogeneity conditions, as we explain in the online appendix.\footnote{If there are no covariates available, we define $\+\beta_i'\*x_{i,t}(0) := 0$ in Assumption 3. In this case, Assumption 4 is obviously not needed.}
  
  Most papers in the literature do not place any parametric assumptions on the covariates.\footnote{One exception is given by \citet{Caetano_Callaway_Payne_Rodrigues_2022}, which is also one of the few studies in the literature to allow for treatment-affected covariates.} However, they assume instead that the covariates are exogenous (to treatment) and iid over the cross-section (see \citealp{Abadie_2005}, \citealp{Callaway_SantAnna_2020}, \citealp{Callaway_Karami_2020}, and \citealp{Caetano_Callaway_Payne_Rodrigues_2022}, to mention a few), which is more restrictive than Assumption 4. In fact, the only studies that come close to ours in terms of the generality of the allowable covariates are \citet{Gobillon_Magnac_2016}, and \citet{Xu_2017}. They allow the covariates to be arbitrarily correlated with the interactive fixed effects, which represents a more general consideration than Assumption 4. However, they require instead that the covariates are stationary and unaffected by treatment, which is not required here.\footnote{They also require that $T$ is large and that the number of common factors, $r$, can be accurately estimated, which is again not a requirement in the present paper.}
  
  \citet{Caetano_Callaway_Payne_Rodrigues_2022} is one of the few papers in the literature to allow for covariates that are affected by treatment. They focus on the ATT; however, they also say that ``it would be interesting to extend our arguments to additionally identifying direct and indirect effects of participating in the treatment'' (page 6). We provide such an extension. In order to separate the part of the ATT that is due to changing values of the covariates from the part that is not, we define
  \begin{align}
  \+\tau_{i,t} := \*x_{i,t} - \*x_{i,t}(0)
  \end{align}
  for a unit $i$ that is member of group $g_i = g > 0$ in post-treatment periods $t > T_0$. In view of Assumption 3, the covariates' contribution to the unit-specific treatment effect on $y_{i,t}$ is given by $\+\beta_i'[\*x_{i,t}(g) - \*x_{i,t}(0)] = \+\beta_i'\+\tau_{i,t}$. We also define the difference between these effects;
  \begin{align}
  \eta_{i,t} :=  \Delta_{i,t} - \+\beta_i'\+\tau_{i,t}.
  \end{align}
  In the terminology of the mediation literature (see, for example, \citealp{huber2014identifying}), $\eta_{i,t}$ is the ``direct'' effect of treatment and $\+\beta_i'\+\tau_{i,t}$ is the ``indirect'' effect of treatment mediated through the covariates.
  
  The random coefficient condition in Assumption 1 is enough if the purpose is to just estimate the ATT. If the purpose is to estimate also the direct and indirect ATTs, henceforth abbreviated ``DATT'' and ``IATT'', respectively, more conditions of the same type are needed.
  
  \bigskip
  
  \noindent \textbf{Assumption 5.} $\+\tau_{i,t}= \+\tau_{g,t} + \+\zeta_{i,t}$ and $\+\beta_{i} = \+\beta + \+\nu_i$, where $\+\tau_{g,t}$ is non-random, and $\+\zeta_{i,t}$ and $\+\nu_i$ are mean zero random errors that are independent of each other as well as of all other random elements of the model.
  
  \bigskip
  
  Assumption 5 implies that
  \begin{align}
  \mathbb{E}(\+\beta_i'\+\tau_{i,t}) = \+\beta'\+\tau_{g,t} =: \mathrm{IATT}_{g,t}.
  \end{align}
  Further use of Assumption 1 gives
  \begin{align}
  \mathbb{E}(\eta_{i,t}) = \mathbb{E}(\Delta_{i,t}) - \mathbb{E}(\+\beta_i'\+\tau_{i,t}) = \mathrm{ATT}_{g,t} - \mathrm{IATT}_{g,t} =: \mathrm{DATT}_{g,t}
  \end{align}
  or, equivalently,
  \begin{align}
  \mathrm{ATT}_{g,t} = \mathrm{DATT}_{g,t} + \mathrm{IATT}_{g,t}.
  \end{align}
  
  The condition that $\+\beta_i$ is randomly distributed with a common mean relaxes the otherwise common homogeneous slope condition (see, for example, \citealp{Gobillon_Magnac_2016}, and \citealp{Xu_2017}) and gives $\+\beta$ a reasonable interpretation as the average effect, similar to the random slopes specification of the ATT. It allows for some heterogeneity across the cross-sectional units without the need for completely unrestricted estimation and has as a result become very popular in the panel data literature (see, for example, \citealp{chudik2011weak}, and \citealp{pesaran2006estimation}). If Assumption 5 is deemed too strong, one can still estimate the ATT itself, which does not place any conditions on $\+\beta_i$.
  
  \section{The TECCE estimator}
  
  \subsection{The ATT}
  
  We need an estimate of $y_{i,t}(0)$ in order to estimate the ATT. Interestingly, because the objective here is to estimate only the ATT and not the other parameters of the model, the estimation of $y_{i,t}(0)$ only requires accounting for the interactive fixed effects, as we now explain.
  
  \bigskip
  
  \noindent \textbf{Counterfactual estimation procedure:}
  
  \begin{enumerate}
  \item For all $t$, compute
  \begin{align}
  \widehat{\*f}_t := \frac{1}{N_0}\sum_{i \in \mathcal{I}_0} \*z_{i,t},\label{fhat}
  \end{align}
  where $\*z_{i,t} := [y_{i,t},\*x_{i,t}']'$ is a $(m+1)\times 1$ vector containing all the observables. The fact that $\widehat{\*f}_t$ is computed with the untreated units only is crucial since in the present paper both $y_{i,t}$ and $\*x_{i,t}$ can depend on the treatment, which may lead to inconsistency if we use the entire sample.
  
  \item Estimate the following regression by OLS for all $i$ and $t \leq T_0$:
  \begin{align}
  y_{i,t} = \*a_i'\widehat{\*f}_t + u_{i,t}, \label{preregr}
  \end{align}
  where $\*a_i$ is a $(m+1)\times 1$ vector of factor loadings and $u_{i,t}$ is an error term. Define the $T_0\times 1$ vector $\*y_{i} := [y_{i,1},...,y_{i,T_0}]'$ and the $T_0\times (m+1)$ matrix $\widehat{\*f} := [\widehat{\*f}_{1},...,\widehat{\*f}_{T_0}]'$. In this notation, the OLS estimator of $\*a_i$ is given by
  \begin{align}
  \widehat{\*a}_i := (\widehat{\*f}'\widehat{\*f})^{-1}\widehat{\*f}'\*y_{i},
  \end{align}
  which is computed for all $i$.
  
  \item The sought counterfactual estimator is given by
  \begin{align}
  \widehat y_{i,t}(0) := \widehat{\*a}_i'\widehat{\*f}_t,
  \end{align}
  which is available for all treated observations $i\in \mathcal{I}_0^c$ and $t > T_0$. Here $\{\widehat{\*a}_i\}_{i\in \mathcal{I}_0^c}$ is from step 2, while $\{\widehat{\*f}_t\}_{t > T_0}$ is from step 1.
  \end{enumerate}
  
  With $y_{i,t}$ known and $y_{i,t}(0)$ estimated, the estimated treatment effect is given by
  \begin{align}
  \widehat \Delta_{i,t} := y_{i,t} - \widehat y_{i,t}(0)  \label{theat}
  \end{align}
  for $i \in \mathcal{I}_0^c$ and $t > T_0$. The TECCE estimator of $\mathrm{ATT}_{g,t}$ for group $g>0$ at time $t$ is obtained by averaging over all group members;
  \begin{align}
  \widehat{\mathrm{ATT}}_{g,t} := \frac{1}{N_g}\sum_{i \in \mathcal{I}_g} \widehat \Delta_{i,t}. \label{atthat}
  \end{align}
  
  A major point about the above estimation procedure is that there is no need to account for the covariates in steps 1 and 2. The intuition for why is as follows: the estimated unit-specific treatment effect can be written as
  \begin{align}
  \widehat \Delta_{i,t} = y_{i,t} - \widehat{\*a}_i'\widehat{\*f}_t = y_{i,t} - \*y_{i}'\widehat{\*f}(\widehat{\*f}'\widehat{\*f})^{-1}\widehat{\*f}_t,
  \end{align}
  which is a ``defactored'' version $y_{i,t}$. Asymptotically the defactoring eliminates the interactive fixed effects. This means that the source of the endogeneity of $\*x_{i,t}$ is gone and therefore the covariates can be ignored without risking omitted variables bias. The defactoring is also the reason for why the procedure works in spite of the fact that $\widehat{\*a}_i$ is not consistent and in fact remains random even asymptotically because $T$ is fixed. The defactoring leads to increased variance; however, the interactive fixed effects are gone and so the asymptotic validity of the procedure is unaffected. Hence, similarly to studies such as \citet{SantAnna_Zhao2020}, our main concern here is not efficiency, but robust estimation and inference. If there are covariates present that are either known not to have a factor structure or there is uncertainty over the process that generated them, the above procedure has to be modified as explained in online appendix.
  
  As \citet{Caetano_Callaway_Payne_Rodrigues_2022} point out, the validity of estimates of the ATT typically depend on whether or not the covariates are affected by treatment status. Most studies circumvent this problem by assuming that there are no covariates at all (see, for example, \citealp{brown2022generalized}), that any covariates are time-invariant (see, for example, \citealp{Callaway_Karami_2020}), or, perhaps most commonly, that the covariates may depend on time but that they are unaffected by treatment (see \citealp{chan2022pcdid}, \citealp{Gobillon_Magnac_2016}, and \citealp{Xu_2017}, to mention a few). The problem here is that if there are time-varying covariates present that depend on the treatment status, approaches that fail to properly control for these will be subject to omitted variables bias. However, the solution is not as simple as just including the relevant treatment-affected covariates into the model. For example, if we are estimating the effect of a certain policy aimed at reducing unemployment, we might want to control for the poverty rate (see \citealp{Caetano_Callaway_Payne_Rodrigues_2022}, for more examples of this type). Because such policies might indirectly reduce poverty, the poverty rate covariate will absorb some of the treatment effect, typically referred to as ``post-treatment bias''. Because of this, treatment-affected covariates are often considered to be ``bad controls'' (see \citealp{angrist2009mostly}). There is therefore a dilemma; while including the covariates induces post-treatment bias, excluding them induces omitted variables bias (see \citealp{aklin2017can}). The defactoring implicit in TECCE not only eliminates the source of the omitted variables bias, but it also enables estimation of the ATT without including the treatment-affected covariates. It therefore resolves the dilemma.
  
  Asymptotic standard errors of estimates of the ATT can be difficult to compute. Many studies therefore resort to bootstrap inference (see, for example, \citealp{Callaway_Karami_2020}, \citealp{Callaway_SantAnna_2020}, and \citealp{Xu_2017}). As we show in the online appendix, bootstrap inference is possible also with TECCE. However, bootstrapping is computationally inconvenient, which means that it does not fit very well with the simple flavor of TECCE. Here we therefore instead follow \citet{brown2022generalized}, and \citet{chan2022pcdid} and employ a version of the non-parametric variance estimator considered by \citet{pesaran2006estimation}:
  \begin{align}
  \widehat{\mathrm{var}}(\widehat{\mathrm{ATT}}_{g,t}) = \frac{1}{N_g-1}\sum_{i \in \mathcal{I}_g} (\widehat \Delta_{i,t}  - \widehat{\mathrm{ATT}}_{g,t})^2.\label{nonparametric variance estimator}
  \end{align}
  In addition to computational simplicity, non-parametric standard errors tend to perform well for CCE in small samples (see \citealp{chudik2011weak}, \citealp{pesaran2006estimation}, and \citealp{westerlund2022cce}).
  
  \subsection{The DATT and IATT}
  
  As we demonstrated in Section 2, the ATT can be decomposed into the DATT and the IATT. We now show how to estimate these constituent parts. The idea behind our estimator of the DATT builds on the discussion of the previous subsection about bad controls. In particular, by making the counterfactual estimation procedure conditional on observed $\*x_{i,t}$, we no longer estimate the ATT but instead estimate the DATT. In other words, including the bad controls induces post-treatment bias that is exactly equal to the DATT.\footnote{The fact that controlling the covariates alters the object being estimated is important not only for the present paper, but also when considering the works of others. As alluded to earlier, many studies assume that the covariates are unaffected by treatment and use the observed covariates in their ATT estimations (see, for example, \citealp{chan2022pcdid}, and \citealp{Xu_2017}). Logic based on our findings suggests that if the unaffected covariates assumption is false, these estimators will only capture the DATT. The Monte Carlo and empirical studies of Sections 5 and 6 elaborate on this point.}
  
  Controlling for $\*x_{i,t}$ requires two changes to the counterfactual estimation procedure presented in Section 3.1. First, the appropriate step-2 regression model to be estimated is no longer given by \eqref{preregr} but by
  \begin{align}
  y_{i,t} = \+\beta'\*x_{i,t} + \*a_i'\widehat{\*f}_t + u_{i,t}.
  \end{align}
  Define the $T_0\times m$ matrix $\*x_{i} := [\*x_{i,1},...,\*x_{i,T_0}]'$ and the $T_0\times T_0$ matrix $\*M_{\*A} := \*I_{T_0} - \*A(\*A'\*A)^{-1}\*A'$, where $\*A$ is any $T_0$-rowed matrix. The estimators of $\+\beta$ and $\*a_i$ in the above model can now be written in the following way:
  \begin{align}
  \widehat{\+\beta} &:= \left(\sum_{i=1}^N  \*x_{i}'\*M_{\widehat{\*f}}\*x_{i}\right)^{-1}\sum_{i=1}^N \*x_{i}' \*M_{\widehat{\*f}}\*y_{i},\\
  \widehat{\*a}_i &:= (\widehat{\*f}'\widehat{\*f})^{-1}\widehat{\*f}'(\*y_{i}-\*x_{i}\widehat{\+\beta}).
  \end{align}
  
  Second, the step-3 counterfactual estimator is now given by
  \begin{align}
  \widehat y_{i,t}(0) := \widehat{\+\beta}'\*x_{i,t} +  \widehat{\*a}_i'\widehat{\*f}_t.
  \end{align}
  
  Given the above changes, the estimated DATT for group $g$ at time $t$ is entirely analogous to the estimated ATT;
  \begin{align}
  \widehat{\mathrm{DATT}}_{g,t} := \frac{1}{N_g}\sum_{i \in \mathcal{I}_g} \widehat \eta_{i,t},
  \end{align}
  where $\widehat \eta_{i,t} := y_{i,t} - \widehat y_{i,t}(0)$. The IATT can be estimated by simply subtracting off $\widehat{\mathrm{DATT}}_{g,t}$ from $\widehat{\mathrm{ATT}}_{g,t}$;
  \begin{align}
  \widehat{\mathrm{IATT}}_{g,t} : = \widehat{\mathrm{ATT}}_{g,t} - \widehat{\mathrm{DATT}}_{g,t} .
  \end{align}
  The variances of the estimated DATT and IATT can be estimated non-parametrically in exactly the same way as the variance of the ATT.\footnote{Let
  $\widehat{\+\tau}_{g,t} := N_g^{-1} \sum_{i \in \mathcal{I}_g} [\*x_{i,t} - \widehat{\*x}_{i,t}(0)]$, where $\widehat{\*x}_{i,t}(0) : = \widehat{\+\lambda}_i'\widehat{\*f}_t$ with $\widehat{\+\lambda}_i := ( \widehat{\*f}' \widehat{\*f} )^{-1} \widehat{\*f}' \*x_i$. Alternative, yet asymptotically equivalent, estimators of the DATT and the IATT can be obtained by replacing $\+\tau_{g,t}$ and $\+\beta$ in the definition of the IATT by $\widehat{\+\tau}_{g,t}$ and $\widehat{\+\beta}$, respectively, and then estimating the DATT as the difference between $\widehat{\mathrm{ATT}}_{g,t}$ and the resulting estimated IATT.}
  
  \section{Asymptotic results}
  
  We can now study the asymptotic properties of the estimated ATT and its direct and indirect parts. Assumptions 1--5 characterize the model. In order to establish the required asymptotic results, more conditions are need.
  
  \bigskip
  
  \noindent \textbf{Assumption 6.} $\+\nu_i$, $\upsilon_{i,t}$, $\+\zeta_{i,t}$, $\varepsilon_{i,t}$ and $\*v_{i,t}$ are all independently distributed across $i$ with finite fourth-order cumulants. Also, $\lim_{N_g\to\infty}N_g^{-1}\sum_{i\in \mathcal{I}_g} \mathbb{E}  (\varepsilon_{i,t}^{2}) = : \sigma^2_{\varepsilon,g,t}$ and the $m \times m$ matrix $\lim_{N_g\to\infty}N_g^{-1}\sum_{i\in \mathcal{I}_g}\mathbb{E}  (\*v_{i,t}\*v_{i,t}') =: \+\Sigma_{\*v,g,t}$ exist and are positive definite.
  
  \bigskip
  
  \noindent \textbf{Assumption 7.} The $r\times (m+1)$ matrix $\+\Lambda_i := [\+\alpha_i +\+\lambda_i\+\beta_i, \+\lambda_i]$ is such that $N_0^{-1}\sum_{i \in \mathcal{I}_{0}} \+\Lambda_i$ has full row rank $r$ almost surely.
  
  \bigskip
  
  \noindent \textbf{Assumption 8.} $T_0 > m+1$.
  
  \bigskip
  
  \noindent \textbf{Assumption 9.} The $r \times r$ matrix $\sum_{t=1}^{T_0}\*f_t\*f_t'$ is positive definite.
  
  \bigskip
  
  \noindent \textbf{Assumption 10.} The $m \times m$ matrix $\mathrm{plim}_{N\to\infty}N^{-1}\sum_{i=1}^N \*x_{i}'\*M_{\widehat{\*f}} \*x_{i}$ exist and is positive definite.
  
  \bigskip
  
  Assumption 6 is not particularly restrictive in the sense that $y_{i,t}$ and $\*x_{i,t}$ are still allowed to be strongly cross-sectionally correlated through $\*f_{t}$.\footnote{We illustrated this point using $\*x_{i,t}(0)$. By Assumptions 4 and 6, $\mathbb{E}[\*x_{i,t}(0)\*x_{j,t}(0)'] = \+\lambda_i'\*f_t\*f_t'\+\lambda_j$, which is not zero unless the loadings are. Interactive fixed effects therefore provide a means to accommodate strong cross-sectional dependence (see \citealp{chudik2011weak}, for a thorough discussion of the notions of weak and strong cross-sectional dependence).}  While we do require that the covariance matrices of $\varepsilon_{i,t}$ and $\*v_{i,t}$ are positive definite, we place no such restrictions on the covariance matrices of $\+\nu_i$, $\upsilon_{i,t}$ and $\+\zeta_{i,t}$. Parameter heterogeneity is therefore not a requirement.
  
  Step 1 of the counterfactual estimation procedure uses the cross-sectional averages of the observables to estimate the factors. We therefore require that those averages are informative about the factors. Assumption 7 rules out situations in which there are factors present but their effect on $\widehat{\*f}_t$ averages out. Another situation that is ruled out by this assumption is when $m+1 \geq r$, so that the number of factors is larger than the number of cross-sectional averages used to estimate them.\footnote{See \citet{Juodis_etal_2021} for a discussion and some results for the case when Assumption 7 fails.} One way to relax this condition is if some of the factors are observed, because Assumption 7 only applies to the loadings of unobserved factors. Observed factors can be appended to $\*f_t$ in Assumptions 3 and 4, and to $\widehat{\*f}_t$ in step 1 of the counterfactual estimation procedure. The rest is unaffected. In Section 6, we elaborate on this point and explain how to test Assumption 7.
  
  Assumptions 8--10 are non-collinearity conditions. Assumptions 8 and 9 ensure that the $(m+1)\times (m+1)$ matrix $\widehat{\*f}'\widehat{\*f}$ appearing in the step-2 estimator of $\*a_i$ is positive definite both asymptotically and in small samples.\footnote{Because our estimator of $\*a_i$ comes from a regression on pre-treatment observations, we need at least as many degrees of freedom as allowable factors. This assumption is similar in principle to requiring at least two time periods for a fixed effects regression.} Assumption 10 generalizes the usual ``within assumption'' in the unit-specific fixed effects only model, which rules out time-invariant covariates. Assumption 10 rules out more general ``low-rank'' covariates, such as deterministic constant and trend terms that only vary over time, as it is almost always done in models with interactive effects (see \citealp{moon2015linear}, for a discussion). The reason for this condition is that if there are such low rank covariates present, they will be captured by $\widehat{\*f}_t$, and therefore they cannot be included also in $\*x_{i}$. Fortunately, there is an easy fix to this problem, which is to treat all low rank covariates as observed factors and to append them to $\widehat{\*f}$.
  
  An important point about Assumptions 6--10 is that the time series properties of $\*f_t$, $\varepsilon_{i,t}$ and $\*v_{i,t}$ are essentially unrestricted. Note in particular how, unlike most other treatment effects studies, stationarity and homoskedasticity are not needed.
  
  We are now ready to state Theorem 1, which contains our first main result.
  
  \bigskip
  
  \noindent \textbf{Theorem 1.} \emph{Suppose that Assumptions 1--4 and 6--9 are met. Then, uniformly in $g \in \{1,...,G\}$ and $t\in \{T_0+1,...,T\}$, as $N_g,\,N_0\to\infty$ with $N_g/N_0 \to \tau < \infty$,}
  \begin{align}
  \frac{\sqrt{N_g}(\widehat{\mathrm{ATT}}_{g,t} - \mathrm{ATT}_{g,t})}{\sqrt{\mathrm{var}(\widehat{\mathrm{ATT}}_{g,t})}} \to_d N(0, 1 ),
  \end{align}
  \emph{where $\to_d$ signifies convergence in distribution and the definition of $\mathrm{var}(\widehat{\mathrm{ATT}}_{g,t})$ is provided in the online appendix.}
  
  \bigskip
  
  Theorem 1 does not require that Assumptions 5 and 10 hold, which is natural since the estimation of the ATT does not require explicit conditioning on $\*x_{i,t}$. Asymptotic normality therefore holds without any restrictions on $\+\beta_i$ and only minimal conditions on $\*x_{i,t}$.
  
  Theorem 1 implies that $\widehat{\mathrm{ATT}}_{g,t}$ is consistent for $\mathrm{ATT}_{g,t}$ and that the rate of convergence is $N^{-1/2}$. In the treatment effects literature it is common to plot estimates of the ATT over time and to interpret variations as being due to treatment effect dynamics. Theorem 1 says that $\widehat{\mathrm{ATT}}_{g,t}$ can be used for the same purpose. If one is not interested in dynamics but just want a summary measure of the evidence, $\widehat{\mathrm{ATT}}_{g,t}$ can be averaged over $g$ or $t$.\footnote{See \citet{Callaway_SantAnna_2020} for a thorough discussion of various ways in which $\mathrm{ATT}_{g,t}$ can be meaningfully averaged.} Since $G$ and $T-T_0$ are both fixed, the consistency in Theorem 1 naturally carries over to such averages.
  
  Inference based on Theorem 1 requires a consistent estimator of $\mathrm{var}(\widehat{\mathrm{ATT}}_{g,t})$. Unrestricted treatment effect heterogeneity is known to be problematic for variance estimation in the sense that exact asymptotic inference is not always possible (see, for example, \citealp{borusyak2021revisiting}, and \citealp{deChaisemartin_DHaultfoeuille_2020}). Another problem is the presence of unobserved common factors and the additional estimation uncertainty that they bring. This problem does not necessarily interfere with asymptotic inference; however, it does require additional conditions to ensure that the factor estimation error is negligible. \citet{chan2022pcdid} assume that $N_0$, $N$ and $T$ are all large. They deal with the problem by requiring that $T/N_0 \to 0$. The appropriate condition in the present context is given by $N_g/N_0 \to 0$. In empirical work this means that while $N_g$ should be large, $N_0$ should be larger.
  
  \bigskip
  
  \noindent \textbf{Theorem 2.} \emph{Suppose that the conditions of Theorem 1 are met. Then, uniformly in $g \in \{1,...,G\}$ and $t\in \{ T_0+1,...,T \}$, as $N_g,\,N_0\to\infty$ with $N_g/N_0 \to 0$,}
  \begin{align}
  \widehat{\mathrm{var}}(\widehat{\mathrm{ATT}}_{g,t}) \to_p \mathrm{var}(\widehat{\mathrm{ATT}}_{g,t}),
  \end{align}
  \emph{where $\to_p$ signifies convergence in probability.}
  
  \bigskip
  
  Theorems 1 and 2 enable construction of test statistics and confidence intervals that are asymptotically valid for a particular constellation of $g$ and $t$. Let us therefore consider the common problem of testing the null hypothesis of $H_0: \mathrm{ATT}_{g,t} = 0$ using the following $t$-statistic:
  \begin{align}
  T_{g,t} : = \frac{\sqrt{N_g}\widehat{\mathrm{ATT}}_{g,t}}{\sqrt{\widehat{\mathrm{var}}(\widehat{\mathrm{ATT}}_{g,t})}} ,
  \end{align}
  which by Theorems 1 and 2 is asymptotically $N(0,1)$ under $H_0$. This test statistic is useful when $G$ and $T-T_0$ are small. As $G$ and $T-T_0$ increases, however, so does the number of tests that can be computed. A simple approach would be to compute one test for each $(g,t)$-pair and to reject the null hypothesis of no treatment effect if at least one of the tests rejects at a particular significance level. However, this means ignoring the multiplicity of the testing problem, which is likely to result in too many rejections. Fortunately, testing multiple time periods and/or groups is almost as easy as testing a particular $(g,t)$-pair. Suppose as an example that we are interested in testing if $H_0$ holds for all groups in a particular time period. This hypothesis can be tested using the following Wald-type test statistic: $\sum_{g=1}^G T_{g,t}^2$, which has a limiting $\chi^2(G)$ distribution under the null. Alternatively, we may consider the empirical rejection frequency of $T_{1,t},...,T_{G,t}$, as given by $G^{-1}\sum_{g=1}^G 1(|T_{g,t}| > c_\alpha)$, where $1(A)$ is the indicator function for the event $A$ and $c_\alpha$ is the appropriate right-tail $\alpha$-level critical value from $N(0,1)$. If $H_0$ holds for all groups, the empirical rejection frequency should be close to $2\alpha$ for $G$ sufficiently large (see \citealp{Bai_Ng_2006}).\footnote{The Wald-type statistic and empirical rejection frequency are two examples of how a test statistic like $T_{g,t}$ can be combined but there are many more (see, for example, \citealp{Bai_Ng_2006}, for a discussion in the context of testing interactive effects).}
  
  A major point about Theorems 1 and 2 is that they hold even if $r$ is unknown, provided only that $m+1 \geq r$, so that the number of factors is not under-specified. As we show in the proof, while $\mathrm{var}(\widehat{\mathrm{ATT}}_{g,t})$ depends on whether $m+1 = r$ or $m+1 > r$, this dependence is successfully mimicked in large samples by $\widehat{\mathrm{var}}(\widehat{\mathrm{ATT}}_{g,t})$. Asymptotically valid inference is therefore possible for any $r$ satisfying $m+1 \geq r$.
  
  The asymptotic approximations in Theorems 1 and 2 are not expected to be perfect in small samples. We propose a simple bootstrap algorithm to obtain bootstrapped $p$-values and confidence intervals, and prove their asymptotic validity in the appendix.
  
  \bigskip
  
  \noindent \textbf{Theorem 3.} \emph{Suppose that Assumptions 1--10 are met. Then, the results reported in Theorems 1 and 2 for $\widehat{\mathrm{ATT}}_{g,t}$ apply also to $\widehat{\mathrm{DATT}}_{g,t}$ and $\widehat{\mathrm{IATT}}_{g,t}$.}
  
  \bigskip
  
  Theorem 3 implies that the above discussion of Theorems 1 and 2 for $\widehat{\mathrm{ATT}}_{g,t}$ applies also to $\widehat{\mathrm{DATT}}_{g,t}$ and $\widehat{\mathrm{IATT}}_{g,t}$. The variance estimates are formed the same way as the $\widehat{\mathrm{ATT}}_{g,t}$ and definitions are given in the online appendix.
  
  \section{Monte Carlo simulations}
  
  In this section, we use Monte Carlo simulations as a means to study the small-sample properties of TECCE. Following the bulk of the previous literature, we assume that there is just one treated group, so that $G=1$ and $g \in \{0,1\}$. Similarly to \citet{chan2022pcdid}, we set $T_0 = T/2$ and $\mathcal{I}_0 = \{1,...,N/2\}$, so that $t_1 = T/2+1$, $N_0 = N/2$ and $\mathcal{I}_0^c = \mathcal{I}_1 = \{N/2+1,...,N\}$. The first half of the cross-sectional units are therefore untreated and for the second half treatment starts midway through the sample period.
  
  The potential untreated outcome and covariates, $y_{i,t}(0)$ and $\*x_{i,t}(0)$, respectively, are generated according to Assumptions 1, 3 and 5 with $r=m= \+\beta = 1$. As in the heterogenous slope experiments of \citet{pesaran2006estimation}, we make $\+\nu_i$ a draw from $N(0,\kappa^2)$ with $\kappa = 0.2$.
  
  The factor loadings in the equations for $y_{i,t}(0)$ and $\*x_{i,t}(0)$ are generated with $\+\alpha_i =  \theta 1(i \in \mathcal{I}_1) + e_i$ and $\+\lambda_i = e_i$, where $\theta\in \{0,1\}$ and $e_i \sim N(1,1)$. The term $\theta 1(i \in \mathcal{I}_1)$ introduces a break in the average loadings. If $\theta = 0$, then $\mathbb{E}(\+\alpha_i) = 1$ for all $i$, whereas if $\theta = 1$, then $\mathbb{E}(\+\alpha_i) = 1+1(i \in \mathcal{I}_1)$, so that average loading for treated units is different from that of untreated units. The fact that $e_i$ is present in both equations makes $\+\alpha_i$ and $\+\lambda_i$ correlated, which in turn means that $\*x_{i,t}(0)$ is endogenous. The loadings are drawn once and are then held fixed across replications. They are therefore non-random in the simulations. This is important because while breaks-in-loadings specifications are common (see, for example, \citealp{chan2022pcdid}, \citealp{Gobillon_Magnac_2016}, and \citealp{Xu_2017}), here the break does not determine whether or not trends are parallel, but just amplifies any non-parallel trending.
  
  Three specifications of $\*f_t$ are considered. In the first, $\*f_{t} = 1$ is a constant, while the second, $\*f_{t} = t$ is a linear trend. In the third and final specification, $\*f_t$ follows an AR(1) process $\*f_{t} = (1-\rho) + \rho \*f_{t-1} + u_{t}$, where $\rho = 0.5$, $\*f_{0} = 0$ and $u_{t} \sim N(0,1)$. Just like the loadings, the factor is drawn once and is then kept fixed across replications. The interactive effects are therefore fixed, which in turn means that the only specification in which trends are parallel is when $\*f_{t} = 1$. The errors $\varepsilon_{i,t}$ and $\*v_{i,t}$ are generated as AR(1) processes with autoregressive coefficient 0.5, similarly to the third specification of $\*f_{t}$ but with zero mean.
  
  The treated outcome and covariate are generated as
  \begin{align}
  y_{i,t} & = \eta_{i} + \+\beta_i'\*x_{i,t} + \+\alpha_i'\*f_t + \varepsilon_{i,t}, \\
  \*x_{i,t} & = \+\tau_{i} + \+\lambda_i'\*f_t + \*v_{i,t}
  \end{align}
  for $i \in \mathcal{I}_1$ and $t \geq t_1$. Here, $\eta_i$ and $\+\tau_i$ are the direct effects of treatment to $y_{i,t}$ and $\*x_{i,t}$, which we assume for simplicity to be constant over time. Hence, in this section, $\mathrm{ATT}_{g,t} = \mathrm{ATT}_{g}= \mathrm{ATT}_{1} = \mathbb{E}(\eta_{i}) + \+\beta'\mathbb{E}(\+\tau_{i})= \mathbb{E}(\eta_{i}) + \mathbb{E}(\+\tau_{i})$. We consider two specifications of $\+\tau_{i}$, $\+\tau_{i} = 0$ and $\+\tau_{i} \sim N(1,\kappa^2)$, and one specification of $\eta_i$, $\eta_i \sim N(1,\kappa^2)$. This means that $\mathrm{ATT}_{1} = 1$ if $\+\tau_{i} = 0$ and $\mathrm{ATT}_{1} = 2$ if $\+\tau_{i} \sim N(1,\kappa^2)$.
  
  The TECCE estimator is implemented exactly as described in Section 3. We focus on the ATT itself. The results for the DATT and IATT were very similar and are available upon request. The TECCE results are compared to those obtained by regressing $y_{i,t}$ onto a treatment dummy and $\*x_{i,t}$ using two-way fixed effects OLS, which represents the workhorse of the treatment effects literature. We also simulate the ``PCDID--MG'' estimator of \citet{chan2022pcdid}, and the ``GSC'' estimator of \citet{Xu_2017}, which are two of the closest competitors to TECCE. Both estimators are implemented while treating the number of factors, $r$, as known. This is unlike TECCE, which in view of the fact that $m+1 = 2 > r = 1$ here is overestimating the number of factors. This is one difference that should be taken into account when considering the results as ``overestimating" the number of factors should lean to efficiency losses for TECCE. Another difference is that while the OLS and PCDID estimators require that the ATT is time-invariant, the TECCE and GSC estimators do not. Hence, since in this section $\mathrm{ATT}_{1}$ is constant over time, the OLS and PCDID estimators make use of a true restriction. For each estimator, we report the average bias and the root mean squared error (RMSE) of the estimated ATT, which in case of GSC and TECCE is the estimated ATT for time period $t_1 = T_0+1$. The number of replications is set to 2,000.
  
  \begin{center}
  {\sc Insert Tables \ref{tab:mc_no_break} and \ref{tab:mc_break} about here}
  \end{center}
  
  Tables \ref{tab:mc_break} and \ref{tab:mc_no_break} report the results for the cases when the loadings are subject to a structural break and when they are not, respectively. In both cases, $\+\tau_{i} = 0$ and therefore the covariate is unaffected by treatment. Since trends are parallel when $\*f_{t} = 1$, all four estimators considered are expected to work well in this case, which is just what we see in the tables. The ranking in terms of RMSE is also as expected with the PCDID--MG and OLS estimators that make use of the restriction that the ATT is time-invariant outperforming the GSC estimator, which in turn outperforms TECCE. The fact that the RMSE is generally lower for GSC than for TECCE is to be expected given the conjecture of \citet{bai2009panel} that his PC-based approach is asymptotically efficient under normal errors, and that overestimation of the number of factors is known to lead to finite sample inefficiency (see \citealp{moon2015linear}). The performance in terms RMSE is reflected also in the bias results with the PCDID--MG and OLS estimators generally coming out on top, although the differences are very small. The overall best performance in terms of bias is obtained by using the TECCE, whereas in terms of RMSE, GSC is best.
  
  The above picture is quite different when $\*f_{t}$ is no longer constant, so that trends are not parallel. The PCDID--MG and OLS estimators, that previously performed well, have large bias and RMSE, especially in the case when loadings are breaking. The fact that the OLS estimator does not work is just as expected, because with $\*f_{t}$ time varying two-way fixed effects are not enough to control for the endogeneity induced by the interactive fixed effects. The fact that PCDID--MG also does not work is consistent with the discussion in \citet{pesaran2006estimation} where the point is made that PC based on OLS residuals, which is how PCDID is constructed, will in general be inconsistent, because it makes use of an inconsistent estimator of the model parameters.
  
  \begin{center}
  {\sc Insert Table \ref{tab:mc_x_affect} about here}
  \end{center}
  
  Table \ref{tab:mc_x_affect} is the same as Tables \ref{tab:mc_no_break}, except that now $\+\tau_{i} \sim N(1,\kappa^2)$, so that the covariate is affected by treatment. As expected given the discussion of Section 3, except for TECCE, all estimators are seriously biased. \citet{chan2022pcdid} point out that in PCDID covariates may be correlated with, yet not causally affected by, treatment. Of course, in practice one never knows whether an observed correlation is in fact causal or not. The results in Table \ref{tab:mc_x_affect} illustrate the risk involved.
  
  All-in-all, we find that the TECCE estimator performs well and that it is essentially unbiased in the type of small-$T$ panels considered here. In fact, good performance in terms of bias seems remarkably robust. The estimator is not the most efficient, which is also not expected given its simplicity.
  
  \section{Empirical illustration}
  
  Since its membership in the WTO in 2001, China's role in the world economy has grown enormously. As a result, the pro-competitive effects of China's WTO accession have attracted considerable attention, so much so that there is by now a separate strand of literature devoted to them. The bulk of the evidence seems to suggest that both the level and dispersion of markups have gone down following the WTO entry, and that this development has had important welfare effects (see, for example, \citealp{Hsu_etal_2020}).
  
  The standard approach to studying WTO membership on market characteristics is to exploit differences in tariffs across industries. For example, one can split industries into a treatment and a control group, where the former is relatively more exposed to the WTO accession. Given that pre-WTO tariffs varied greatly across industries, industries that had previously been protected with high tariffs experienced greater tariff reduction. They should therefore be relatively more exposed to the ``treatment''. The effect of the WTO accession is then estimated via a difference-in-differences-style OLS regression in which markup is regressed onto a dummy variable that takes on the value one for treated industries in post-WTO periods, control variables, and industry and time fixed effects.
  
  While popular, the standard approach to WTO evaluation has (at least) two drawbacks. First, it requires the parallel trends assumption, which may not be realistic in this context. A commonly cited reason is that certain industries have more lobbying power for protection and are thus less responsive to changes in the macroeconomy. Tariffs may be granted to domestic special interest groups, the pressure of which may vary over time (see, for example, \citealp{Fan_etal_2018}, \citealp{Deng_etal_2018}, and \citealp{Xiang_etal_2017}). Differences in lobbying power may therefore cause the treatment and control groups to differ systematically over time, even if China had not joined the WTO in 2001.\footnote{Similarly, policymakers may lower tariffs selectively in industries that are able to compete with relatively less expensive imports, for example, in industries experiencing a productivity boom (see \citealp{Brandt_etal_2017}).} Because many sources of possible non-parallel trending are unknown and lack good proxies, it is common to control for industry-specific linear time trends (see, for example, \citealp{Liu_Qiu_2016}, and \citealp{Mao_Xu_2019}). Deterministic trends can account for some non-parallel trending but not all. Moreover, results tend to be highly sensitive to the inclusion of such trends.\footnote{Some studies include common controls that are thought to be highly correlated with various kinds of protectionism, such as wage rates, employment, exports, and imports (see, for example, \citealp{Hsu_etal_2020}). Again the results tend to be very sensitive.}
  
  The second main drawback of the standard approach is that it cannot handle covariates that are affected by treatment. This issue is important because the literature has identified many channels through which the WTO accession may affect markups (see \citealp{Mao_Xu_2019}, \citealp{Fan_etal_2018}, \citealp{Deng_etal_2018}, \citealp{Liu_Ma_2021}, and \citealp{Brandt_etal_2017}, to mention a few). Two common examples are the price- and cost-change channels. Markup is defined as the ratio of price to marginal cost. Thus, markup changes can come from price changes, cost changes, or both. It is therefore common to include one of these variables as a covariate, and to estimate the effect of the WTO accession on it to understand the causal mechanism of treatment (see, for example, \citealp{Mao_Xu_2019}, \citealp{Fan_etal_2018}, and \citealp{lu2015trade}). But then we know from Section 3 that treatment-affected covariates require special treatment or else the estimated ATT will be misleading. Specifically, the inclusion of such covariates will absorb some effect of treatment. The following quotation, taken from \citet[page 116]{Fan_etal_2018}, suggests that researchers are aware of this problem: ``If the marginal-cost channel indeed plays a role, then once the marginal costs are included as an explanatory variable, we would witness attenuation of the impact of input tariffs on markups.''
  
  The present paper is not the first to point to these shortcomings, but it is the first to consider an econometric approach that is designed to deal with both. The TECCE approach allows for interactive fixed effects in which there may be unobserved differences between cross-sectional units that change over time as a result of common shocks. The parallel trend condition is therefore not required, which is a substantial advantage when compared to the standard fixed effects-based approach. Another advantage of the approach that we exploit in this section is that it not only allows for covariates that may be affected by treatment but that it makes it possible to assess the relative importance of the direct and indirect treatment channels. It should therefore be well suited for the problem at hand.
  
  The data set that we use is taken from \citet{lu2015trade} (see also \citealp{Deng_etal_2018}, who use the same data), and comprises 164 industries (three-digit Chinese industrial classification) observed over the 1998--2005 period. The smallness of $T$ here, which is a feature of most data sets in the literature, means that it is important to use techniques that work even if $T$ is not large. The Monte Carlo results reported in Section 5 suggest that the proposed TECCE approach should work well. Following \citet{lu2015trade}, the outcome variable is markup dispersion, as measured by the markup Theil index (in logs). Industries are split in half into the treatment and control groups based on whether they faced tariffs above or below the sample median in 2001.
  
  We focus on the \citet{lu2015trade} study in part because of their analysis of the price- and cost-change channels (see their Section E). The authors use the TFP Theil index as a proxy for marginal costs. They argue that its inclusion allows them to partially isolate the price-change channel. In order to assess the ATT of the WTO accession on costs, the authors run a second OLS regression with the TFP Theil index as dependent variable and markup dispersion as a covariate. The estimated ATTs are significant, which is taken as evidence that both channels are operational. The purpose of this illustration is to assess the whether or not the treatment affects the controls.
  
  The above discussion suggests that in terms of the notation of Section 2, $y_{i,t}$ is the markup Theil index and $\*x_{i,t}$ is the TFP Theil index. The estimated factors in $\widehat{\*f}_t$ are made up of the cross-sectional averages of these variables. A constant is included as an observed factor (as explained in Section 4), which is tantamount to allowing for industry fixed effects. We therefore allow for one known and two unknown factors. In order to assess if this is enough, we apply the rank classifier of \citet{De_Vos_2024test}. The estimated number of factors and rank of the matrix of average factor loadings are equal to one and two, respectively, suggesting that Assumption 7 is met.
  
  \begin{center}
  {\sc Insert Figure \ref{fig:trade} about here}
  \end{center}
  
  The estimated overall and indirect ATTs are reported in Figure \ref{fig:trade}. The estimates are reported for each year and averaged over all the post- and pre-treatment periods, as is customary in the literature. Both types are reported together with 95\% confidence intervals. We first note that both the total and indirect ATT estimates are negative, suggesting that markup dispersion decreased more in industries that had relatively high tariffs in 2001. Given that industries with higher initial tariffs experienced greater tariff reduction, these results imply that the WTO accession reduced markup dispersion. We also note that all pre-treatment estimates are close to zero, which implies that our method adequately captures the non-parallel trending in markups before 2001.
  
  While insignificant in 2002 and 2003, the year-specific total ATTs reported in Figure \ref{fig:trade} (a) are significant in 2004 and 2005. The point estimate in 2003 is notably noisy. A possible reason for this is that the industry classification system changed in 2003, as noted by, for example, \citet{Chen_etal_2019}, and \citet{lu2015trade}. The estimated average ATT during the whole post-treatment period is about $-0.1$ and significant, consistent with the results of \citet{Chen_etal_2019}.
  
  We also look at the estimated indirect ATT to understand the impact of productivity changes on markups. According to the results reported in Figure \ref{fig:trade} (b), the estimated IATTs are negative and significant in the post-treatment period and insignificant in the pre-treatment period. \citet{lu2015trade} estimate the ATT on the TFP Theil index and find it to be significantly negative; however, their approach does not allow them to infer whether this negative response of the TFP Theil index has an effect on the markup Theil index. According to our results, the estimated IATTs are sizable, accounting for almost half of the total ATTs. This result is important in itself, but also for what it means for the results in \citet{lu2015trade}, which are based on including the TFP Theil index as a covariate. In particular, we know from before that this type of conditioning will absorb the indirect effect. In this case, since both ATTs are estimated to be negative, and the magnitude of the indirect ATTs are about half of the overall ATTs, conditioning on the TFP Theil index will lead to an underestimation of the total ATTs by about 50\%.
  
  \section{Conclusion}
  
  In this paper, we propose a new estimator of the ATT, dubbed ``TECCE'', that is applicable in fixed-$T$ panels when the parallel trends condition fails because of the presence of interactive fixed effects. Being CCE-based, TECCE relies on the presence of covariates that load on the same factors as the outcome variable. This assumption allows us to use the cross-sectional averages of the observables to estimate the untreated potential outcomes in post-treatment time periods. The covariates are allowed to depend on the treatment status so that TECCE makes it possible separate the direct ATT that is unrelated to the covariates from the indirect ATT that works through those covariates. The estimator is shown to be consistent and asymptotically normal, thereby enabling standard inference, provided only that the number of cross-sectional units, $N$, is large. This condition is a great advantage in practice because in the literature, many data sets involve only a few time periods $T$. We consider one such small-$T$ data set in our empirical illustration and estimate the effect of China's accession into the WTO on the dispersion of industry-level markups.
  
  \pagebreak
  
  \bibliography{references}
  
  \pagebreak
  
  \begin{table}[H]
  \caption{Monte Carlo results without break in loadings and treatment-affected covariates.}\label{tab:mc_no_break}
  \hskip 12 pt
  \centering
  \par
  \begin{tabular}{rrcccccccccc}
  \hline\hline
   {\small $$} & {\small $$} & {\small $$} & \multicolumn{4}{c}{\small Bias} & {\small $$} & \multicolumn{4}{c}{\small RMSE}\\ \cline{4-7}\cline{9-12}
   {\small $N$} & {\small $T$} & {\small $$} & {\small CCE} & {\small GSC} & {\small PC} & {\small OLS} & {\small $$} & {\small CCE} & {\small GSC} & {\small PC} & {\small OLS} \\\hline
   \multicolumn{12}{c}{\small Common factor specification: Constant}\\
   {\small $40$} & {\small $8$} & {\small $$} & {\small $0.027$} & {\small $-0.027$} & {\small $-0.009$} & {\small $-0.010$} & {\small $$} & {\small $0.653$} & {\small $0.328$} & {\small $0.315$} & {\small $0.328$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.011$} & {\small $-0.061$} & {\small $0.000$} & {\small $-0.001$} & {\small $$} & {\small $0.621$} & {\small $0.286$} & {\small $0.226$} & {\small $0.231$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $-0.001$} & {\small $-0.027$} & {\small $-0.002$} & {\small $-0.002$} & {\small $$} & {\small $0.306$} & {\small $0.156$} & {\small $0.185$} & {\small $0.165$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.010$} & {\small $-0.033$} & {\small $-0.003$} & {\small $0.002$} & {\small $$} & {\small $0.233$} & {\small $0.118$} & {\small $0.134$} & {\small $0.117$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.031$} & {\small $0.005$} & {\small $0.003$} & {\small $-0.004$} & {\small $$} & {\small $0.491$} & {\small $0.312$} & {\small $0.233$} & {\small $0.290$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.024$} & {\small $0.000$} & {\small $0.006$} & {\small $0.006$} & {\small $$} & {\small $0.400$} & {\small $0.239$} & {\small $0.166$} & {\small $0.197$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.012$} & {\small $-0.013$} & {\small $-0.001$} & {\small $-0.002$} & {\small $$} & {\small $0.279$} & {\small $0.159$} & {\small $0.125$} & {\small $0.140$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.009$} & {\small $-0.010$} & {\small $0.002$} & {\small $0.001$} & {\small $$} & {\small $0.200$} & {\small $0.115$} & {\small $0.095$} & {\small $0.100$} \\
   \multicolumn{12}{c}{\small Common factor specification: AR(1) process}\\
   {\small $40$} & {\small $8$} & {\small $$} & {\small $0.036$} & {\small $0.024$} & {\small $0.553$} & {\small $-0.147$} & {\small $$} & {\small $0.908$} & {\small $0.416$} & {\small $0.721$} & {\small $0.376$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.015$} & {\small $0.021$} & {\small $0.500$} & {\small $0.101$} & {\small $$} & {\small $0.609$} & {\small $0.303$} & {\small $0.646$} & {\small $0.294$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $-0.003$} & {\small $-0.083$} & {\small $-0.357$} & {\small $0.080$} & {\small $$} & {\small $0.385$} & {\small $0.247$} & {\small $0.448$} & {\small $0.226$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.005$} & {\small $-0.014$} & {\small $-0.787$} & {\small $0.097$} & {\small $$} & {\small $0.206$} & {\small $0.105$} & {\small $0.842$} & {\small $0.178$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.014$} & {\small $-0.019$} & {\small $-0.098$} & {\small $0.017$} & {\small $$} & {\small $0.550$} & {\small $0.309$} & {\small $0.377$} & {\small $0.291$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.009$} & {\small $0.011$} & {\small $-0.355$} & {\small $0.136$} & {\small $$} & {\small $0.348$} & {\small $0.214$} & {\small $0.418$} & {\small $0.320$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.015$} & {\small $-0.042$} & {\small $0.039$} & {\small $0.092$} & {\small $$} & {\small $0.350$} & {\small $0.179$} & {\small $0.317$} & {\small $0.197$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.006$} & {\small $-0.032$} & {\small $0.042$} & {\small $-0.059$} & {\small $$} & {\small $0.212$} & {\small $0.121$} & {\small $0.481$} & {\small $0.129$} \\
   \multicolumn{12}{c}{\small Common factor specification: Linear trend}\\
   {\small $40$} & {\small $8$} & {\small $$} & {\small $0.008$} & {\small $-0.003$} & {\small $0.769$} & {\small $-0.316$} & {\small $$} & {\small $0.785$} & {\small $0.381$} & {\small $0.917$} & {\small $0.646$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.019$} & {\small $0.020$} & {\small $0.589$} & {\small $0.277$} & {\small $$} & {\small $0.744$} & {\small $0.330$} & {\small $0.695$} & {\small $0.480$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $-0.001$} & {\small $0.001$} & {\small $0.501$} & {\small $-0.166$} & {\small $$} & {\small $0.370$} & {\small $0.184$} & {\small $0.557$} & {\small $0.325$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.014$} & {\small $0.003$} & {\small $0.334$} & {\small $-0.037$} & {\small $$} & {\small $0.294$} & {\small $0.139$} & {\small $0.378$} & {\small $0.205$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.019$} & {\small $0.007$} & {\small $0.695$} & {\small $-0.308$} & {\small $$} & {\small $0.551$} & {\small $0.362$} & {\small $0.826$} & {\small $0.842$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.020$} & {\small $0.008$} & {\small $0.621$} & {\small $0.018$} & {\small $$} & {\small $0.453$} & {\small $0.268$} & {\small $0.696$} & {\small $0.554$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.005$} & {\small $-0.003$} & {\small $0.270$} & {\small $-0.007$} & {\small $$} & {\small $0.310$} & {\small $0.177$} & {\small $0.353$} & {\small $0.398$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.005$} & {\small $0.004$} & {\small $0.566$} & {\small $0.005$} & {\small $$} & {\small $0.229$} & {\small $0.128$} & {\small $0.608$} & {\small $0.279$} \\
  \hline\hline
  \end{tabular}
  \par
      \begin{tablenotes}[flushleft]\small
      \item \textit{Notes}: ``CCE'', ``GSC'', ``PC'' and ``OLS'' refer to the proposed TECCE estimator, GSC estimator of \citet{Xu_2017}, the PCDID--MG estimator of \citet{chan2022pcdid}, and the two-way fixed effects OLS estimator, respectively. ``Bias'' and ``RMSE'' refer to the average bias and the root mean squared error, respectively, across replications.
      \end{tablenotes}
  \end{table}
  
  
  
  \begin{table}[H]
  \caption{Monte Carlo results with break in loadings but without treatment-affected covariates.}\label{tab:mc_break}
  \hskip 12 pt
  \centering
  \par
  \begin{tabular}{rrcccccccccc}
  \hline\hline
   {\small $$} & {\small $$} & {\small $$} & \multicolumn{4}{c}{\small Bias} & {\small $$} & \multicolumn{4}{c}{\small RMSE}\\ \cline{4-7}\cline{9-12}
   {\small $N$} & {\small $T$} & {\small $$} & {\small CCE} & {\small GSC} & {\small PC} & {\small OLS} & {\small $$} & {\small CCE} & {\small GSC} & {\small PC} & {\small OLS} \\\hline
   \multicolumn{12}{c}{\small Common factor specification: Constant}\\
   {\small $40$} & {\small $8$} & {\small $$} & {\small $0.034$} & {\small $-0.029$} & {\small $-0.009$} & {\small $-0.010$} & {\small $$} & {\small $0.785$} & {\small $0.512$} & {\small $0.315$} & {\small $0.328$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.009$} & {\small $-0.111$} & {\small $0.000$} & {\small $-0.001$} & {\small $$} & {\small $0.778$} & {\small $0.436$} & {\small $0.226$} & {\small $0.231$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $-0.001$} & {\small $-0.063$} & {\small $-0.002$} & {\small $-0.002$} & {\small $$} & {\small $0.382$} & {\small $0.220$} & {\small $0.185$} & {\small $0.165$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.012$} & {\small $-0.068$} & {\small $-0.003$} & {\small $0.002$} & {\small $$} & {\small $0.298$} & {\small $0.170$} & {\small $0.134$} & {\small $0.117$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.042$} & {\small $0.014$} & {\small $0.003$} & {\small $-0.004$} & {\small $$} & {\small $0.579$} & {\small $0.429$} & {\small $0.233$} & {\small $0.290$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.037$} & {\small $-0.004$} & {\small $0.006$} & {\small $0.006$} & {\small $$} & {\small $0.510$} & {\small $0.350$} & {\small $0.166$} & {\small $0.197$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.017$} & {\small $-0.025$} & {\small $-0.001$} & {\small $-0.002$} & {\small $$} & {\small $0.369$} & {\small $0.223$} & {\small $0.125$} & {\small $0.140$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.014$} & {\small $-0.022$} & {\small $0.002$} & {\small $0.001$} & {\small $$} & {\small $0.257$} & {\small $0.164$} & {\small $0.095$} & {\small $0.100$} \\
   \multicolumn{12}{c}{\small Common factor specification: AR(1) process}\\
   {\small $40$} & {\small $8$} & {\small $$} & {\small $0.056$} & {\small $0.112$} & {\small $1.163$} & {\small $0.610$} & {\small $$} & {\small $1.129$} & {\small $0.705$} & {\small $1.367$} & {\small $0.701$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.020$} & {\small $0.053$} & {\small $1.255$} & {\small $1.454$} & {\small $$} & {\small $0.766$} & {\small $0.475$} & {\small $1.490$} & {\small $1.480$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $-0.005$} & {\small $-0.576$} & {\small $-1.325$} & {\small $-1.427$} & {\small $$} & {\small $0.517$} & {\small $1.317$} & {\small $1.480$} & {\small $1.442$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.008$} & {\small $-0.028$} & {\small $-2.312$} & {\small $-1.832$} & {\small $$} & {\small $0.264$} & {\small $0.148$} & {\small $2.400$} & {\small $1.838$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.018$} & {\small $-0.042$} & {\small $-0.246$} & {\small $-0.425$} & {\small $$} & {\small $0.708$} & {\small $0.489$} & {\small $0.738$} & {\small $0.514$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.011$} & {\small $0.034$} & {\small $-1.588$} & {\small $-2.297$} & {\small $$} & {\small $0.436$} & {\small $0.446$} & {\small $1.650$} & {\small $2.314$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.020$} & {\small $-0.076$} & {\small $0.136$} & {\small $1.127$} & {\small $$} & {\small $0.450$} & {\small $0.264$} & {\small $0.824$} & {\small $1.141$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.007$} & {\small $-0.062$} & {\small $0.095$} & {\small $-0.968$} & {\small $$} & {\small $0.276$} & {\small $0.177$} & {\small $1.149$} & {\small $0.975$} \\
   \multicolumn{12}{c}{\small Common factor specification: Linear trend}\\
   {\small $40$} & {\small $8$} & {\small $$} & {\small $0.009$} & {\small $0.043$} & {\small $2.431$} & {\small $3.641$} & {\small $$} & {\small $0.950$} & {\small $0.733$} & {\small $2.581$} & {\small $3.683$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.020$} & {\small $0.029$} & {\small $1.844$} & {\small $4.239$} & {\small $$} & {\small $0.947$} & {\small $0.497$} & {\small $1.947$} & {\small $4.257$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $0.000$} & {\small $0.001$} & {\small $2.108$} & {\small $3.817$} & {\small $$} & {\small $0.463$} & {\small $0.257$} & {\small $2.167$} & {\small $3.827$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.019$} & {\small $0.009$} & {\small $1.526$} & {\small $3.962$} & {\small $$} & {\small $0.369$} & {\small $0.196$} & {\small $1.559$} & {\small $3.967$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.028$} & {\small $0.036$} & {\small $2.551$} & {\small $7.513$} & {\small $$} & {\small $0.653$} & {\small $0.611$} & {\small $2.679$} & {\small $7.553$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.028$} & {\small $0.013$} & {\small $3.446$} & {\small $8.018$} & {\small $$} & {\small $0.579$} & {\small $0.413$} & {\small $3.514$} & {\small $8.037$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.004$} & {\small $-0.004$} & {\small $2.325$} & {\small $7.993$} & {\small $$} & {\small $0.409$} & {\small $0.262$} & {\small $2.384$} & {\small $8.003$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.008$} & {\small $0.007$} & {\small $2.593$} & {\small $8.005$} & {\small $$} & {\small $0.294$} & {\small $0.190$} & {\small $2.652$} & {\small $8.010$} \\
  \hline\hline
  \end{tabular}
  \par
      \begin{tablenotes}[flushleft]\small
      \item \textit{Notes}: ``CCE'', ``GSC'', ``PC'' and ``OLS'' refer to the proposed TECCE estimator, GSC estimator of \citet{Xu_2017}, the PCDID--MG estimator of \citet{chan2022pcdid}, and the two-way fixed effects OLS estimator, respectively. ``Bias'' and ``RMSE'' refer to the average bias and the root mean squared error, respectively, across replications.
      \end{tablenotes}
  \end{table}
  
  
  
  \begin{table}[H]
  \caption{Monte Carlo results without break in loadings but with treatment-affected covariates.}\label{tab:mc_x_affect}
  \hskip 12 pt
  \centering
  \par
  \begin{tabular}{rrcccccccccc}
  \hline\hline
   {\small $$} & {\small $$} & {\small $$} & \multicolumn{4}{c}{\small Bias} & {\small $$} & \multicolumn{4}{c}{\small RMSE}\\ \cline{4-7}\cline{9-12}
   {\small $N$} & {\small $T$} & {\small $$} & {\small CCE} & {\small GSC} & {\small PC} & {\small OLS} & {\small $$} & {\small CCE} & {\small GSC} & {\small PC} & {\small OLS} \\\hline
   \multicolumn{12}{c}{\small Common factor specification: Constant}\\
  {\small $40$} & {\small $8$} & {\small $$} & {\small $0.028$} & {\small $-1.051$} & {\small $-1.011$} & {\small $-1.008$} & {\small $$} & {\small $0.657$} & {\small $1.106$} & {\small $1.065$} & {\small $1.064$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.011$} & {\small $-1.068$} & {\small $-1.000$} & {\small $-0.997$} & {\small $$} & {\small $0.625$} & {\small $1.108$} & {\small $1.028$} & {\small $1.027$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $-0.001$} & {\small $-1.032$} & {\small $-1.002$} & {\small $-1.000$} & {\small $$} & {\small $0.307$} & {\small $1.045$} & {\small $1.016$} & {\small $1.020$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.010$} & {\small $-1.037$} & {\small $-0.998$} & {\small $-1.003$} & {\small $$} & {\small $0.234$} & {\small $1.044$} & {\small $1.005$} & {\small $1.013$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.030$} & {\small $-1.004$} & {\small $-1.003$} & {\small $-0.996$} & {\small $$} & {\small $0.494$} & {\small $1.056$} & {\small $1.046$} & {\small $1.026$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.025$} & {\small $-1.003$} & {\small $-0.994$} & {\small $-0.995$} & {\small $$} & {\small $0.404$} & {\small $1.034$} & {\small $1.014$} & {\small $1.010$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.014$} & {\small $-1.013$} & {\small $-1.002$} & {\small $-1.002$} & {\small $$} & {\small $0.282$} & {\small $1.026$} & {\small $1.012$} & {\small $1.010$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.008$} & {\small $-1.012$} & {\small $-0.999$} & {\small $-0.997$} & {\small $$} & {\small $0.202$} & {\small $1.019$} & {\small $1.004$} & {\small $1.002$} \\
   \multicolumn{12}{c}{\small Common factor specification: AR(1) process}\\
   {\small $40$} & {\small $8$} & {\small $$} & {\small $0.036$} & {\small $-1.023$} & {\small $-1.322$} & {\small $-0.606$} & {\small $$} & {\small $0.911$} & {\small $1.119$} & {\small $1.369$} & {\small $0.791$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.014$} & {\small $-0.990$} & {\small $-1.416$} & {\small $-1.032$} & {\small $$} & {\small $0.610$} & {\small $1.038$} & {\small $1.445$} & {\small $1.122$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $-0.002$} & {\small $-1.279$} & {\small $-1.609$} & {\small $-1.988$} & {\small $$} & {\small $0.385$} & {\small $1.377$} & {\small $1.623$} & {\small $2.004$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.006$} & {\small $-1.024$} & {\small $-1.534$} & {\small $-2.203$} & {\small $$} & {\small $0.207$} & {\small $1.030$} & {\small $1.541$} & {\small $2.218$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.014$} & {\small $-1.053$} & {\small $-1.331$} & {\small $-1.374$} & {\small $$} & {\small $0.553$} & {\small $1.114$} & {\small $1.363$} & {\small $1.426$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.009$} & {\small $-1.002$} & {\small $-1.603$} & {\small $-1.823$} & {\small $$} & {\small $0.349$} & {\small $1.029$} & {\small $1.628$} & {\small $1.835$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.013$} & {\small $-1.047$} & {\small $-1.611$} & {\small $-1.567$} & {\small $$} & {\small $0.353$} & {\small $1.062$} & {\small $1.621$} & {\small $1.596$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.006$} & {\small $-1.035$} & {\small $-1.609$} & {\small $-1.382$} & {\small $$} & {\small $0.213$} & {\small $1.042$} & {\small $1.613$} & {\small $1.472$} \\
   \multicolumn{12}{c}{\small Common factor specification: Linear trend}\\
   {\small $40$} & {\small $8$} & {\small $$} & {\small $0.009$} & {\small $-1.098$} & {\small $-2.129$} & {\small $-0.834$} & {\small $$} & {\small $0.788$} & {\small $1.180$} & {\small $2.201$} & {\small $1.015$} \\
   {\small $80$} & {\small $8$} & {\small $$} & {\small $0.020$} & {\small $-1.021$} & {\small $-1.545$} & {\small $-1.104$} & {\small $$} & {\small $0.748$} & {\small $1.077$} & {\small $1.599$} & {\small $1.180$} \\
   {\small $160$} & {\small $8$} & {\small $$} & {\small $-0.001$} & {\small $-1.059$} & {\small $-2.019$} & {\small $-1.108$} & {\small $$} & {\small $0.372$} & {\small $1.076$} & {\small $2.039$} & {\small $1.144$} \\
   {\small $320$} & {\small $8$} & {\small $$} & {\small $0.014$} & {\small $-1.056$} & {\small $-1.899$} & {\small $-1.373$} & {\small $$} & {\small $0.295$} & {\small $1.065$} & {\small $1.910$} & {\small $1.388$} \\
   {\small $40$} & {\small $16$} & {\small $$} & {\small $0.017$} & {\small $-1.262$} & {\small $-2.246$} & {\small $-1.085$} & {\small $$} & {\small $0.555$} & {\small $1.319$} & {\small $2.388$} & {\small $1.189$} \\
   {\small $80$} & {\small $16$} & {\small $$} & {\small $0.021$} & {\small $-1.129$} & {\small $-1.927$} & {\small $-1.043$} & {\small $$} & {\small $0.456$} & {\small $1.163$} & {\small $2.005$} & {\small $1.098$} \\
   {\small $160$} & {\small $16$} & {\small $$} & {\small $0.006$} & {\small $-1.164$} & {\small $-1.966$} & {\small $-1.486$} & {\small $$} & {\small $0.312$} & {\small $1.178$} & {\small $2.007$} & {\small $1.506$} \\
   {\small $320$} & {\small $16$} & {\small $$} & {\small $0.005$} & {\small $-1.152$} & {\small $-1.946$} & {\small $-1.192$} & {\small $$} & {\small $0.230$} & {\small $1.159$} & {\small $1.967$} & {\small $1.217$} \\
  \hline\hline
  \end{tabular}
  \par
      \begin{tablenotes}[flushleft]\small
      \item \textit{Notes}: See Table \ref{tab:mc_no_break} for an explanation.
      \end{tablenotes}
  \end{table}
  
  
  
  \begin{figure}
      \caption{Estimated ATTs of China's WTO accession in 2001 on the markup Theil index.}
      \label{fig:trade}
  
      \begin{subfigure}[b]{\textwidth}
          \caption{Estimated total ATT}
          \begin{adjustbox}{width=\textwidth}
            \input{figures/trade-cce_est.tex}
          \end{adjustbox}
      \end{subfigure}
  
      \begin{subfigure}[b]{\textwidth}
          \caption{Estimated indirect ATT via TFP dispersion}
          \begin{adjustbox}{width=\textwidth}
            \input{figures/trade-cce_mediated_est.tex}
          \end{adjustbox}
      \end{subfigure}
  
      {\footnotesize\emph{Notes:} The figures present ATT estimates and 95\% confidence intervals for the effect of China's WTO accession in 2001 on the dispersion of markups as measured by the markup Theil index. The treatment group comprise all industries that in 2001 had above-median tariff rates. Estimates are computed using the TECCE estimator with the TFP Theil index as a covariate. A constant is included as an observed factor. Figure (a) presents estimates of the total ATT and figure (b) presents the estimated indirect ATT operating through the TFP Theil index. $\hat{\beta}$ in figure (b) refers to the estimated slope on the TFP Theil index in the markup Theil index regression.}
  \end{figure}  

\end{document}
